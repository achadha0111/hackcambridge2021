{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to be scraped:\n",
    "1. News Headline \n",
    "2. Rating \n",
    "3. News Outlet \n",
    "4. URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen as ureq\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coronavirus Headlines\n",
    "Scraping COVID-19 articles from 'allsides.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allsides.com/topics/coronavirus?search=coronavirus#gsc.tab=0&gsc.q=coronavirus&gsc.page=1'\n",
    "uclient = ureq(url)\n",
    "page_html = uclient.read()\n",
    "uclient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html parsing\n",
    "soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "\n",
    "# grabs each grid\n",
    "containers = soup.findAll(\"div\", {\"class\":\"topic_combine\"})\n",
    "\n",
    "article_links = []\n",
    "article_headlines = []\n",
    "\n",
    "\n",
    "for link in containers:\n",
    "    headlines = link.findAll(\"div\", {\"class\":\"news-title\"})\n",
    "    for urls in headlines:\n",
    "        news_title = urls.findAll(\"a\", href=True)\n",
    "        \n",
    "        # Appending the article links to this list\n",
    "        article_links.append(news_title[0]['href'])\n",
    "        \n",
    "        # Appending the article headlines to this list\n",
    "        article_headlines.append(news_title[0].text)\n",
    "        \n",
    "# Scraping the news outlet names\n",
    "\n",
    "agencies = soup.findAll(\"div\",{\"class\": \"source-area\"})\n",
    "\n",
    "article_outlets = []\n",
    "article_ratings =[]\n",
    "\n",
    "for agency in agencies:\n",
    "    outlets = agency.findAll(\"div\", {\"class\":\"news-source\"})\n",
    "    for outlet in outlets:\n",
    "        article_outlet = outlet.findAll(\"a\", href=True)\n",
    "            \n",
    "        # Appending the article outlet\n",
    "        article_outlets.append(article_outlet[0].text)\n",
    "\n",
    "# Scraping the political rating\n",
    "\n",
    "for agency in soup.findAll(\"div\",{\"class\": \"field-content\"}):\n",
    "    for img in agency:\n",
    "        article_ratings.append(img.get('title'))\n",
    "\n",
    "# Making a dataframe that combines all scraped lists\n",
    "\n",
    "Covid_Headlines = DataFrame(\n",
    "    {'Headline': Series(article_headlines),\n",
    "     'Outlet': Series(article_outlets),\n",
    "     'Rating': Series(article_ratings),\n",
    "     'Link': Series(article_links)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Change Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allsides.com/topics/climate-change?search=climate%20change#gsc.tab=0&gsc.q=climate%20change&gsc.page=1'\n",
    "uclient = ureq(url)\n",
    "page_html = uclient.read()\n",
    "uclient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html parsing\n",
    "soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "\n",
    "# grabs each grid\n",
    "containers = soup.findAll(\"div\", {\"class\":\"topic_combine\"})\n",
    "\n",
    "article_links = []\n",
    "article_headlines = []\n",
    "\n",
    "\n",
    "for link in containers:\n",
    "    headlines = link.findAll(\"div\", {\"class\":\"news-title\"})\n",
    "    for urls in headlines:\n",
    "        news_title = urls.findAll(\"a\", href=True)\n",
    "        \n",
    "        # Appending the article links to this list\n",
    "        article_links.append(news_title[0]['href'])\n",
    "        \n",
    "        # Appending the article headlines to this list\n",
    "        article_headlines.append(news_title[0].text)\n",
    "        \n",
    "# Scraping the news outlet names\n",
    "\n",
    "agencies = soup.findAll(\"div\",{\"class\": \"source-area\"})\n",
    "\n",
    "article_outlets = []\n",
    "article_ratings =[]\n",
    "\n",
    "for agency in agencies:\n",
    "    outlets = agency.findAll(\"div\", {\"class\":\"news-source\"})\n",
    "    for outlet in outlets:\n",
    "        article_outlet = outlet.findAll(\"a\", href=True)\n",
    "            \n",
    "        # Appending the article outlet\n",
    "        article_outlets.append(article_outlet[0].text)\n",
    "\n",
    "# Scraping the political rating\n",
    "\n",
    "for agency in soup.findAll(\"div\",{\"class\": \"field-content\"}):\n",
    "    for img in agency:\n",
    "        article_ratings.append(img.get('title'))\n",
    "\n",
    "# Making a dataframe that combines all scraped lists\n",
    "\n",
    "Climate_Headlines = DataFrame(\n",
    "    {'Headline': Series(article_headlines),\n",
    "     'Outlet': Series(article_outlets),\n",
    "     'Rating': Series(article_ratings),\n",
    "     'Link': Series(article_links)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free Speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allsides.com/topics/free-speech?search=free%20speech#gsc.tab=0&gsc.q=free%20speech&gsc.page=1'\n",
    "uclient = ureq(url)\n",
    "page_html = uclient.read()\n",
    "uclient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Headline  \\\n",
      "0   Facebook passes final decision to ban Trump to...   \n",
      "1   Big Tech Critics Alarmed At Direction of Biden...   \n",
      "2   Violence at Capitol and beyond reignites a deb...   \n",
      "3   How Trump’s fights with tech transformed Repub...   \n",
      "4   Twitter Temporarily Suspends QAnon Rep. For El...   \n",
      "5   Why Twitter’s “censorship” is not the same as ...   \n",
      "6   Judge Refuses To Reinstate Parler After Amazon...   \n",
      "7   Ocasio-Cortez: Facebook, Zuckerberg 'bear part...   \n",
      "8   Does banning Trump really make social media sa...   \n",
      "9   Jared Kushner and Dan Scavino reportedly teame...   \n",
      "10  Why Purging Social Media of Extremist Speech M...   \n",
      "11  Josh Hawley’s Book On Big Tech Picked Up By Co...   \n",
      "12  Cancel culture has no place whatsoever in busi...   \n",
      "13  Conservative Leaders: Tech Companies Pose Exis...   \n",
      "14  AOC and other progressives have a new goal: Si...   \n",
      "15                                                NaN   \n",
      "16                                                NaN   \n",
      "17                                                NaN   \n",
      "18                                                NaN   \n",
      "19                                                NaN   \n",
      "\n",
      "                           Outlet  \\\n",
      "0   American Enterprise Institute   \n",
      "1                            ACLU   \n",
      "2             Pew Research Center   \n",
      "3                      ProCon.org   \n",
      "4                           Kialo   \n",
      "5               ABC News (Online)   \n",
      "6                   The Intercept   \n",
      "7               CNN (Online News)   \n",
      "8                        Politico   \n",
      "9                        HuffPost   \n",
      "10                         Quartz   \n",
      "11              NPR (Online News)   \n",
      "12                       The Hill   \n",
      "13                 Yahoo! The 360   \n",
      "14                The Week - News   \n",
      "15                         Reason   \n",
      "16                 The Daily Wire   \n",
      "17         Fox News (Online News)   \n",
      "18                    NewsBusters   \n",
      "19           New York Post (News)   \n",
      "\n",
      "                                          Rating  \\\n",
      "0                                           None   \n",
      "1    Political News Media Bias Rating: Lean Left   \n",
      "2                                           None   \n",
      "3         Political News Media Bias Rating: Left   \n",
      "4         Political News Media Bias Rating: Left   \n",
      "5                                           None   \n",
      "6    Political News Media Bias Rating: Lean Left   \n",
      "7                                           None   \n",
      "8         Political News Media Bias Rating: Left   \n",
      "9                                           None   \n",
      "10  Political News Media Bias Rating: Lean Right   \n",
      "11                                          None   \n",
      "12       Political News Media Bias Rating: Right   \n",
      "13  Political News Media Bias Rating: Lean Right   \n",
      "14                                          None   \n",
      "15       Political News Media Bias Rating: Right   \n",
      "16                                          None   \n",
      "17  Political News Media Bias Rating: Lean Right   \n",
      "18                                           NaN   \n",
      "19                                           NaN   \n",
      "\n",
      "                                                 Link  \n",
      "0   https://www.allsides.com/news/2021-01-21-1307/...  \n",
      "1   https://www.allsides.com/news/2021-01-20-1426/...  \n",
      "2   https://www.allsides.com/news/2021-01-19-0705/...  \n",
      "3   https://www.allsides.com/news/2021-01-18-1816/...  \n",
      "4   https://www.allsides.com/news/2021-01-18-0928/...  \n",
      "5   https://www.allsides.com/news/2021-01-21-1316/...  \n",
      "6   https://www.allsides.com/news/2021-01-21-1256/...  \n",
      "7   https://www.allsides.com/news/2021-01-16-1406/...  \n",
      "8   https://www.allsides.com/news/2021-01-14-0502/...  \n",
      "9   https://www.allsides.com/news/2021-01-13-1534/...  \n",
      "10  https://www.allsides.com/news/2021-01-18-1851/...  \n",
      "11  https://www.allsides.com/news/2021-01-18-1227/...  \n",
      "12  https://www.allsides.com/news/2021-01-17-1442/...  \n",
      "13  https://www.allsides.com/news/2021-01-15-1022/...  \n",
      "14  https://www.allsides.com/news/2021-01-14-1943/...  \n",
      "15                                                NaN  \n",
      "16                                                NaN  \n",
      "17                                                NaN  \n",
      "18                                                NaN  \n",
      "19                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "# html parsing\n",
    "soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "\n",
    "# grabs each grid\n",
    "containers = soup.findAll(\"div\", {\"class\":\"topic_combine\"})\n",
    "\n",
    "article_links = []\n",
    "article_headlines = []\n",
    "\n",
    "\n",
    "for link in containers:\n",
    "    headlines = link.findAll(\"div\", {\"class\":\"news-title\"})\n",
    "    for urls in headlines:\n",
    "        news_title = urls.findAll(\"a\", href=True)\n",
    "        \n",
    "        # Appending the article links to this list\n",
    "        article_links.append(news_title[0]['href'])\n",
    "        \n",
    "        # Appending the article headlines to this list\n",
    "        article_headlines.append(news_title[0].text)\n",
    "        \n",
    "# Scraping the news outlet names\n",
    "\n",
    "agencies = soup.findAll(\"div\",{\"class\": \"source-area\"})\n",
    "\n",
    "article_outlets = []\n",
    "article_ratings =[]\n",
    "\n",
    "for agency in agencies:\n",
    "    outlets = agency.findAll(\"div\", {\"class\":\"news-source\"})\n",
    "    for outlet in outlets:\n",
    "        article_outlet = outlet.findAll(\"a\", href=True)\n",
    "            \n",
    "        # Appending the article outlet\n",
    "        article_outlets.append(article_outlet[0].text)\n",
    "\n",
    "# Scraping the political rating\n",
    "\n",
    "for agency in soup.findAll(\"div\",{\"class\": \"field-content\"}):\n",
    "    for img in agency:\n",
    "        article_ratings.append(img.get('title'))\n",
    "\n",
    "# Making a dataframe that combines all scraped lists\n",
    "\n",
    "Speech_Headlines = DataFrame(\n",
    "    {'Headline': Series(article_headlines),\n",
    "     'Outlet': Series(article_outlets),\n",
    "     'Rating': Series(article_ratings),\n",
    "     'Link': Series(article_links)\n",
    "    })\n",
    "\n",
    "print(Speech_Headlines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
